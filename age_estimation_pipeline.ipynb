{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c7b0ae",
   "metadata": {},
   "source": [
    "\n",
    "# Estimation d'âge à partir d'images — PyTorch (Régression **ou** Classification douce)\n",
    "\n",
    "Ce notebook permet de **choisir** entre deux approches :\n",
    "- **Régression** (MAE/Huber)\n",
    "- **Classification douce** avec **soft labels** (distribution 0..100 ans + espérance)\n",
    "\n",
    "Il inclut :\n",
    "- parsing des noms `XXXXXX_YZWW.ext`,\n",
    "- split **par personne (ID)** pour éviter la fuite d'info,\n",
    "- `AgeDataset` + DataLoaders,\n",
    "- deux modèles : `AgeRegressor` et `AgeClassifier`,\n",
    "- boucles d'entraînement/évaluation adaptées,\n",
    "- inférence test + **export CSV** + sauvegarde des poids.\n",
    "\n",
    "> ⚙️ Change le bloc **Configuration** pour sélectionner la méthode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f1f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# Configuration générale\n",
    "# =========================\n",
    "from pathlib import Path\n",
    "\n",
    "# Dossiers à adapter\n",
    "TRAIN_DIR = Path(\"data/train\")   # chemin vers les images d'entraînement\n",
    "TEST_DIR  = Path(\"data/test\")    # chemin vers les images de test\n",
    "\n",
    "# Choix de la méthode: 'regression' ou 'classification'\n",
    "METHOD = \"classification\"  # <-- change ici\n",
    "\n",
    "# Paramètres communs\n",
    "BACKBONE = \"convnext_tiny\"       # ex: \"resnet50\", \"efficientnetv2_s\", \"convnext_tiny\"\n",
    "USE_SEX  = True                  # utilise la variable sexe (1=M, 0=F) concaténée aux features\n",
    "MAX_AGE  = 100                   # bornes d'âge (0..MAX_AGE)\n",
    "IMG_SIZE = 224                   # taille d'entrée\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS     = 20\n",
    "LR         = 3e-4\n",
    "WD         = 1e-4\n",
    "SEED       = 42\n",
    "\n",
    "# Pour classification douce\n",
    "HIDDEN_DIM = 512\n",
    "SIGMA_SOFT = 2.0                 # écart-type pour soft labels gaussiens\n",
    "\n",
    "# Fichier de sortie\n",
    "EXPERIMENT_NAME = f\"age_{METHOD}_{BACKBONE}_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "BEST_WEIGHTS = f\"{EXPERIMENT_NAME}_best.pt\"\n",
    "SUBMISSION_CSV = f\"{EXPERIMENT_NAME}_submission.csv\"\n",
    "\n",
    "print(\"Méthode:\", METHOD)\n",
    "print(\"Backbone:\", BACKBONE)\n",
    "print(\"Train dir:\", TRAIN_DIR.resolve())\n",
    "print(\"Test dir:\", TEST_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aa7c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# Imports & seed\n",
    "# =========================\n",
    "import os, re, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45335305",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# Parsing des noms & Dataset\n",
    "# =========================\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\", \".JPG\", \".JPEG\", \".PNG\"}\n",
    "_AGE_RE = re.compile(r'^(?P<pid>\\d+)_(?P<idx>\\d{1,2})(?P<sex>[MF])(?P<age>\\d{2})$')\n",
    "\n",
    "def parse_name(fname: str):\n",
    "    stem = Path(fname).stem\n",
    "    m = _AGE_RE.match(stem)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Nom non conforme: {fname}\")\n",
    "    d = m.groupdict()\n",
    "    return int(d[\"pid\"]), int(d[\"idx\"]), d[\"sex\"], int(d[\"age\"])\n",
    "\n",
    "def age_bucket(age, width=5):\n",
    "    return age // width\n",
    "\n",
    "class AgeDataset(Dataset):\n",
    "    def __init__(self, img_dir, items, transform=None):\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.items = items  # list of dicts: {\"path\": str, \"age\": int, \"sex\": 0/1}\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        it = self.items[i]\n",
    "        path = self.img_dir / it[\"path\"]\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        age = torch.tensor([it[\"age\"]], dtype=torch.float32)\n",
    "        sex = torch.tensor([it[\"sex\"]], dtype=torch.float32)\n",
    "        return img, age, sex, it[\"path\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d87ae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# Construction DF & split par personne (ID)\n",
    "# =========================\n",
    "rows = []\n",
    "for p in sorted(TRAIN_DIR.iterdir()):\n",
    "    if p.suffix in IMG_EXTS:\n",
    "        pid, idx, sex, age = parse_name(p.name)\n",
    "        rows.append({\"filename\": p.name, \"person_id\": pid, \"photo_idx\": idx,\n",
    "                     \"sex\": sex, \"age\": age})\n",
    "df = pd.DataFrame(rows)\n",
    "df[\"age_bucket\"] = df[\"age\"].apply(age_bucket)\n",
    "print(\"Images train:\", len(df), \"| personnes uniques:\", df.person_id.nunique())\n",
    "display(df.head()) if len(df) else None\n",
    "\n",
    "# StratifiedGroupKFold: stratifie par age_bucket tout en groupant par person_id\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "X = np.zeros(len(df))\n",
    "y = df[\"age_bucket\"].values\n",
    "groups = df[\"person_id\"].values\n",
    "\n",
    "train_idx, val_idx = next(iter(sgkf.split(X, y, groups)))\n",
    "\n",
    "train_df = df.iloc[train_idx].copy()\n",
    "val_df   = df.iloc[val_idx].copy()\n",
    "\n",
    "assert set(train_df.person_id) & set(val_df.person_id) == set(), \"Fuite détectée: IDs communs.\"\n",
    "\n",
    "print(\"Split -> train images:\", len(train_df), \"val images:\", len(val_df))\n",
    "\n",
    "# Build items for Dataset\n",
    "def to_items(subdf):\n",
    "    items = []\n",
    "    for _, r in subdf.iterrows():\n",
    "        items.append({\n",
    "            \"path\": r[\"filename\"],\n",
    "            \"age\": int(r[\"age\"]),\n",
    "            \"sex\": 1 if r[\"sex\"] == \"M\" else 0\n",
    "        })\n",
    "    return items\n",
    "\n",
    "train_items = to_items(train_df)\n",
    "val_items   = to_items(val_df)\n",
    "\n",
    "# Test items\n",
    "test_items = [{\"path\": p.name} for p in sorted(TEST_DIR.iterdir()) if p.suffix in IMG_EXTS]\n",
    "\n",
    "print(\"Aperçu item:\", train_items[0] if train_items else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6547cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# Transforms\n",
    "# =========================\n",
    "mean, std = [0.485,0.456,0.406], [0.229,0.224,0.225]\n",
    "\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8,1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.1,0.1,0.1,0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "    transforms.RandomErasing(p=0.25),\n",
    "])\n",
    "\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_dir, items, transform=None):\n",
    "        self.img_dir = Path(img_dir); self.items = items; self.transform = transform\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __getitem__(self, i):\n",
    "        p = self.items[i][\"path\"]\n",
    "        img = Image.open(self.img_dir / p).convert(\"RGB\")\n",
    "        if self.transform: img = self.transform(img)\n",
    "        sex = torch.tensor([0.5], dtype=torch.float32)  # neutre en test si inconnu\n",
    "        return img, sex, p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d977337",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# DataLoaders\n",
    "# =========================\n",
    "num_workers = 4\n",
    "\n",
    "train_ds = AgeDataset(TRAIN_DIR, train_items, transform=train_tf)\n",
    "val_ds   = AgeDataset(TRAIN_DIR, val_items,   transform=val_tf)\n",
    "test_ds  = TestDataset(TEST_DIR, test_items,  transform=val_tf)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=num_workers, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "len(train_loader), len(val_loader), len(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3da374",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# Modèles\n",
    "# =========================\n",
    "class AgeRegressor(nn.Module):\n",
    "    def __init__(self, backbone_name=BACKBONE, use_sex=USE_SEX):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(backbone_name, pretrained=True, num_classes=0, global_pool=\"avg\")\n",
    "        feat_dim = self.backbone.num_features\n",
    "        self.use_sex = use_sex\n",
    "        in_dim = feat_dim + (1 if use_sex else 0)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(in_dim, 1)\n",
    "        )\n",
    "    def forward(self, x, sex=None):\n",
    "        f = self.backbone(x)\n",
    "        if self.use_sex and sex is not None:\n",
    "            f = torch.cat([f, sex], dim=1)\n",
    "        out = self.head(f)  # (B,1)\n",
    "        return out\n",
    "\n",
    "class AgeClassifier(nn.Module):\n",
    "    def __init__(self, backbone_name=BACKBONE, max_age=MAX_AGE, use_sex=USE_SEX, hidden_dim=HIDDEN_DIM):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(backbone_name, pretrained=True, num_classes=0, global_pool=\"avg\")\n",
    "        feat_dim = self.backbone.num_features\n",
    "        self.use_sex = use_sex\n",
    "        in_dim = feat_dim + (1 if use_sex else 0)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.30),\n",
    "            nn.Linear(hidden_dim, max_age + 1)  # logits 0..max_age\n",
    "        )\n",
    "    def forward(self, x, sex=None):\n",
    "        f = self.backbone(x)\n",
    "        if self.use_sex and sex is not None:\n",
    "            f = torch.cat([f, sex], dim=1)\n",
    "        logits = self.head(f)             # (B, max_age+1)\n",
    "        probs  = torch.softmax(logits, 1)\n",
    "        return logits, probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4906f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# Pertes & utilitaires\n",
    "# =========================\n",
    "def soft_labels(ages_float, max_age=MAX_AGE, sigma=SIGMA_SOFT, device=None):\n",
    "    device = device or ages_float.device\n",
    "    ages_grid = torch.arange(0, max_age+1, device=device).float()  # [0..max_age]\n",
    "    d2 = (ages_grid.unsqueeze(0) - ages_float.unsqueeze(1))**2\n",
    "    dist = torch.exp(-0.5 * d2 / (sigma**2))\n",
    "    dist = dist / (dist.sum(1, keepdim=True) + 1e-8)\n",
    "    return dist\n",
    "\n",
    "def classification_loss(logits, target_soft):\n",
    "    return nn.KLDivLoss(reduction=\"batchmean\")(torch.log_softmax(logits, dim=1), target_soft)\n",
    "\n",
    "# métriques\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    import numpy as np, math\n",
    "    y_true = np.array(y_true, dtype=float)\n",
    "    y_pred = np.array(y_pred, dtype=float)\n",
    "    mae  = np.mean(np.abs(y_pred - y_true))\n",
    "    rmse = math.sqrt(np.mean((y_pred - y_true)**2))\n",
    "    def within_k(k): return 100.0 * np.mean(np.abs(y_pred - y_true) <= k)\n",
    "    # “classification tolérante” ±2 ans\n",
    "    y_ok_true = np.ones_like(y_true)\n",
    "    y_ok_pred = (np.abs(y_pred - y_true) <= 2).astype(int)\n",
    "    P = precision_score(y_ok_true, y_ok_pred, zero_division=0)\n",
    "    R = recall_score(y_ok_true, y_ok_pred, zero_division=0)\n",
    "    F1 = f1_score(y_ok_true, y_ok_pred, zero_division=0)\n",
    "    return {\n",
    "        \"MAE\": mae, \"RMSE\": rmse,\n",
    "        \"Within_1(%)\": within_k(1),\n",
    "        \"Within_2(%)\": within_k(2),\n",
    "        \"Within_3(%)\": within_k(3),\n",
    "        \"Prec_tol±2\": P, \"Rec_tol±2\": R, \"F1_tol±2\": F1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e0c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# Boucles d'entraînement & évaluation\n",
    "# =========================\n",
    "def train_one_epoch_reg(model, loader, optimizer, scaler, device, criterion, max_grad_norm=1.0):\n",
    "    model.train()\n",
    "    loss_sum, n = 0.0, 0\n",
    "    for imgs, ages, sex, _ in loader:\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        ages = ages.to(device, non_blocking=True)\n",
    "        sex  = sex.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(True):\n",
    "            preds = model(imgs, sex).clamp(0, float(MAX_AGE))\n",
    "            loss = criterion(preds, ages)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        bs = imgs.size(0); loss_sum += loss.item() * bs; n += bs\n",
    "    return loss_sum / max(1,n)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_reg(model, loader, device):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    for imgs, ages, sex, _ in loader:\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        ages = ages.to(device, non_blocking=True)\n",
    "        sex  = sex.to(device, non_blocking=True)\n",
    "        preds = model(imgs, sex).clamp(0, float(MAX_AGE)).squeeze(1)\n",
    "        y_true.extend(ages.squeeze(1).cpu().numpy().tolist())\n",
    "        y_pred.extend(preds.cpu().numpy().tolist())\n",
    "    return compute_metrics(y_true, y_pred)\n",
    "\n",
    "def train_one_epoch_cls(model, loader, optimizer, scaler, device, max_grad_norm=1.0):\n",
    "    model.train()\n",
    "    loss_sum, n = 0.0, 0\n",
    "    for imgs, ages, sex, _ in loader:\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        sex  = sex.to(device, non_blocking=True)\n",
    "        ages = ages.squeeze(1).to(device, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(True):\n",
    "            logits, probs = model(imgs, sex)\n",
    "            target = soft_labels(ages, max_age=MAX_AGE, sigma=SIGMA_SOFT)\n",
    "            loss = classification_loss(logits, target)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        bs = imgs.size(0); loss_sum += loss.item() * bs; n += bs\n",
    "    return loss_sum / max(1,n)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_cls(model, loader, device):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    ages_grid = torch.arange(0, MAX_AGE+1, device=device).float()\n",
    "    for imgs, ages, sex, _ in loader:\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        sex  = sex.to(device, non_blocking=True)\n",
    "        ages = ages.squeeze(1).to(device, non_blocking=True)\n",
    "        logits, probs = model(imgs, sex)\n",
    "        pred = torch.sum(probs * ages_grid.unsqueeze(0), dim=1)  # espérance\n",
    "        y_true.extend(ages.cpu().numpy().tolist())\n",
    "        y_pred.extend(pred.cpu().numpy().tolist())\n",
    "    return compute_metrics(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad5220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# Entraînement principal\n",
    "# =========================\n",
    "scaler = torch.amp.GradScaler()\n",
    "best_mae, best_path = 1e9, BEST_WEIGHTS\n",
    "\n",
    "if METHOD == \"regression\":\n",
    "    model = AgeRegressor(BACKBONE, USE_SEX).to(device)\n",
    "    criterion = nn.SmoothL1Loss(beta=1.0)  # Huber\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        tr_loss = train_one_epoch_reg(model, train_loader, optimizer, scaler, device, criterion)\n",
    "        metrics = evaluate_reg(model, val_loader, device)\n",
    "        print(f\"[{epoch:02d}] train_loss={tr_loss:.4f} | MAE={metrics['MAE']:.3f} | W2={metrics['Within_2(%)']:.1f}% | F1tol2={metrics['F1_tol±2']:.3f}\")\n",
    "        if metrics[\"MAE\"] < best_mae:\n",
    "            best_mae = metrics[\"MAE\"]\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "\n",
    "elif METHOD == \"classification\":\n",
    "    model = AgeClassifier(BACKBONE, MAX_AGE, USE_SEX, HIDDEN_DIM).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        tr_loss = train_one_epoch_cls(model, train_loader, optimizer, scaler, device)\n",
    "        metrics = evaluate_cls(model, val_loader, device)\n",
    "        print(f\"[{epoch:02d}] train_loss={tr_loss:.4f} | MAE={metrics['MAE']:.3f} | W2={metrics['Within_2(%)']:.1f}% | F1tol2={metrics['F1_tol±2']:.3f}\")\n",
    "        if metrics[\"MAE\"] < best_mae:\n",
    "            best_mae = metrics[\"MAE\"]\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "\n",
    "print(\"Best MAE:\", best_mae, \"| saved:\", best_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923b04bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# Inférence sur test + export CSV\n",
    "# =========================\n",
    "# Recharge le meilleur modèle\n",
    "if METHOD == \"regression\":\n",
    "    model = AgeRegressor(BACKBONE, USE_SEX).to(device)\n",
    "    model.load_state_dict(torch.load(BEST_WEIGHTS, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    preds, names = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, sex, paths in test_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            sex  = sex.to(device)\n",
    "            y = model(imgs, sex).clamp(0, float(MAX_AGE)).squeeze(1)\n",
    "            preds.extend(torch.round(y).cpu().numpy().tolist())  # arrondi à l'entier pour soumission\n",
    "            names.extend(paths)\n",
    "\n",
    "elif METHOD == \"classification\":\n",
    "    model = AgeClassifier(BACKBONE, MAX_AGE, USE_SEX, HIDDEN_DIM).to(device)\n",
    "    model.load_state_dict(torch.load(BEST_WEIGHTS, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    preds, names = [], []\n",
    "    ages_grid = torch.arange(0, MAX_AGE+1, device=device).float()\n",
    "    with torch.no_grad():\n",
    "        for imgs, sex, paths in test_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            sex  = sex.to(device)\n",
    "            logits, probs = model(imgs, sex)\n",
    "            y = torch.sum(probs * ages_grid.unsqueeze(0), dim=1)\n",
    "            y = torch.round(y).clamp(0, float(MAX_AGE))  # arrondi pour soumission\n",
    "            preds.extend(y.cpu().numpy().tolist())\n",
    "            names.extend(paths)\n",
    "\n",
    "sub_df = pd.DataFrame({\"filename\": names, \"age\": [int(x) for x in preds]})\n",
    "sub_df.to_csv(SUBMISSION_CSV, index=False)\n",
    "print(\"Submission saved:\", SUBMISSION_CSV)\n",
    "sub_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
